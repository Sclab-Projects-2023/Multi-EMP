{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a1376c",
   "metadata": {},
   "source": [
    "## Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ddad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import utils\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "\n",
    "from deepface.detectors import RetinaFaceWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb23c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "  \"VGG-Face\", \n",
    "  \"Facenet\", \n",
    "  \"Facenet512\", \n",
    "  \"OpenFace\", \n",
    "  \"DeepFace\", \n",
    "  \"DeepID\", \n",
    "  \"ArcFace\", \n",
    "  \"Dlib\",\n",
    "]\n",
    "model_name2 = 'enet_b2_8_best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9326c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = os.getcwd()\n",
    "list_vid = glob.glob(basepath+'/visual-features/train/*')\n",
    "list_vid = natsorted(list_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52504d4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Iterate through videos in new_list_vid with a progress bar\n",
    "for vid in tqdm(new_list_vid, desc='Extracting Features'):\n",
    "    # Get the base name of the video file\n",
    "    base_vid = Path(vid).stem\n",
    "    # Create a destination directory for the extracted features\n",
    "    desdir = os.path.join(basepath, 'visual-features', 'facial-train', base_vid)\n",
    "    if not os.path.isdir(desdir):\n",
    "        os.makedirs(desdir)\n",
    "    \n",
    "    # Get all jpg frames from the video directory\n",
    "    frame_paths = glob.glob(vid + '/*.jpg')\n",
    "    # Sort the frame paths in natural order\n",
    "    frame_paths = natsorted(frame_paths)\n",
    "    \n",
    "    # Process each frame in the video\n",
    "    for f, fp in enumerate(frame_paths):\n",
    "        # Get the base name of the frame\n",
    "        base_frame = Path(fp).stem\n",
    "        # Read the image and convert from BGR to RGB\n",
    "        im = cv2.imread(fp)[:, :, ::-1]\n",
    "        # Ensure the image is contiguous in memory\n",
    "        im = np.ascontiguousarray(im, dtype=np.uint8)\n",
    "        \n",
    "        # Detect faces in the image\n",
    "        faces = RetinaFaceWrapper.detect_face(img=im, face_detector=None)\n",
    "        femb1 = []\n",
    "        \n",
    "        # Extract features for each detected face\n",
    "        for i in range(len(faces)):\n",
    "            embedding1 = utils.represent_from_face(face_img=faces[i][0][0],\n",
    "                  model_name = models[2],\n",
    "                  normalization='Facenet',\n",
    "            )\n",
    "            femb1.append(embedding1)\n",
    "        \n",
    "        # Convert the list of embeddings to a numpy array\n",
    "        array_1 = np.array(femb1, dtype=np.float32)\n",
    "        # Save the compressed numpy array of face embeddings\n",
    "        np.savez_compressed(desdir+f'/{base_frame}', fr=array_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dep-new",
   "language": "python",
   "name": "ai_dep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
