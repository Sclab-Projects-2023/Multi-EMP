{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from fer import FER\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_fer_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    detector = FER()\n",
    "    result = detector.detect_emotions(image)\n",
    "    \n",
    "    if result:\n",
    "        emotions = result[0]['emotions']\n",
    "        return list(emotions.values())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_video_folder(video_folder_path):\n",
    "    frame_features = []\n",
    "    image_files = sorted([os.path.join(video_folder_path, file)\n",
    "                          for file in os.listdir(video_folder_path) if file.endswith(\".jpg\")])\n",
    "    \n",
    "    for image_path in image_files:\n",
    "        features = extract_fer_features(image_path)\n",
    "        if features is not None:\n",
    "            frame_features.append(features)\n",
    "    \n",
    "    return frame_features\n",
    "\n",
    "def pad_sequences(sequences, maxlen, feature_dim):\n",
    "    padded_sequences = np.zeros((len(sequences), maxlen, feature_dim))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if length > maxlen:\n",
    "            padded_sequences[i, :maxlen, :] = seq[:maxlen]\n",
    "        else:\n",
    "            padded_sequences[i, :length, :] = seq\n",
    "    return padded_sequences\n",
    "\n",
    "def save_features_by_folder_with_padding(base_folder_path):\n",
    "    video_folders = [os.path.join(base_folder_path, folder)\n",
    "                     for folder in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, folder))]\n",
    "\n",
    "    max_sequence_length = 0\n",
    "    feature_dim = None\n",
    "\n",
    "    # First pass to determine max sequence length and feature dimension\n",
    "    for video_folder in tqdm(video_folders, desc=\"Determining sequence lengths\"):\n",
    "        video_features = process_video_folder(video_folder)\n",
    "        if video_features:\n",
    "            if len(video_features) > max_sequence_length:\n",
    "                max_sequence_length = len(video_features)\n",
    "            if feature_dim is None and video_features:\n",
    "                feature_dim = len(video_features[0])\n",
    "\n",
    "    # Second pass to save padded sequences\n",
    "    for video_folder in tqdm(video_folders, desc=\"Saving padded features\"):\n",
    "        video_features = process_video_folder(video_folder)\n",
    "        if video_features:\n",
    "            padded_features = pad_sequences([video_features], max_sequence_length, feature_dim)\n",
    "            np.save(os.path.join(video_folder, 'features_padded.npy'), padded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3398ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_concatenate_padded_features(base_folder_path):\n",
    "    all_features = []\n",
    "    video_folders = [os.path.join(base_folder_path, folder)\n",
    "                     for folder in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, folder))]\n",
    "    \n",
    "    for video_folder in tqdm(video_folders, desc=\"Loading padded features\"):\n",
    "        features_path = os.path.join(video_folder, 'features_padded.npy')\n",
    "        if os.path.exists(features_path):\n",
    "            features = np.load(features_path)\n",
    "            all_features.append(features)\n",
    "    \n",
    "    # Combine all features into one array\n",
    "    all_features_concatenated = np.concatenate(all_features, axis=0)\n",
    "    return all_features_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path = \"PATH\"\n",
    "val_folder_path = \"PATH\"\n",
    "test_folder_path = \"PATH\"\n",
    "\n",
    "save_features_by_folder_with_padding(train_folder_path)\n",
    "save_features_by_folder_with_padding(val_folder_path)\n",
    "save_features_by_folder_with_padding(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e422747",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_features_concatenated = load_and_concatenate_padded_features(train_folder_path)\n",
    "val_all_features_concatenated = load_and_concatenate_padded_features(val_folder_path)\n",
    "test_all_features_concatenated = load_and_concatenate_padded_features(test_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dep",
   "language": "python",
   "name": "ai_dep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
