{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59aa35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "basepath = os.getcwd()\n",
    "input_dir = os.path.join(basepath, 'visual-features-2', 'train-talker')\n",
    "output_dir = os.path.join(basepath, 'visual-features-pose', 'train-talker')\n",
    "\n",
    "# Get list of VID folders\n",
    "vid_folders = [f for f in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, f))]\n",
    "vid_folders = natsorted(vid_folders)\n",
    "\n",
    "for vid_folder in tqdm(vid_folders, desc='Processing VID folders'):\n",
    "    vid_path = os.path.join(input_dir, vid_folder)\n",
    "    out_vid_path = os.path.join(output_dir, vid_folder)\n",
    "    \n",
    "    if not os.path.exists(out_vid_path):\n",
    "        os.makedirs(out_vid_path)\n",
    "    \n",
    "    frame_paths = glob.glob(os.path.join(vid_path, '*.jpg'))\n",
    "    frame_paths = natsorted(frame_paths)\n",
    "    \n",
    "    for fp in frame_paths:\n",
    "        base_frame = Path(fp).stem\n",
    "        image = cv2.imread(fp)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Pose estimation\n",
    "        results = pose.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            # Extract 3D coordinates\n",
    "            pose_3d = np.array([[lmk.x, lmk.y, lmk.z] for lmk in results.pose_landmarks.landmark])\n",
    "            \n",
    "            # Select only face and upper body parts (e.g., first 25 landmarks)\n",
    "            pose_features = pose_3d[:25]\n",
    "            \n",
    "            # Store features as a 3D array (num_frames x num_landmarks x 3)\n",
    "            pose_features = np.expand_dims(pose_features, axis=0)\n",
    "            \n",
    "            # Save features\n",
    "            np.savez_compressed(os.path.join(out_vid_path, f'{base_frame}'), pose=pose_features)\n",
    "        else:\n",
    "            print(f\"No pose detected in {fp}\")\n",
    "\n",
    "# Release MediaPipe resources\n",
    "pose.close()\n",
    "print(\"Feature extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af4771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_video_features(video_folder, num_frames=3000):\n",
    "    # Select only .npz files\n",
    "    frame_feature_files = [f for f in os.listdir(video_folder) if f.endswith('.npz')]\n",
    "    \n",
    "    # Sort files by frame number extracted from filename\n",
    "    frame_feature_files.sort(key=lambda x: int(re.search(r'frame_(\\d+)', x).group(1)))\n",
    "    \n",
    "    video_features = np.zeros((num_frames, 75), dtype=np.float32)  # Changed to 75 (pose data)\n",
    "    \n",
    "    for file_name in frame_feature_files:\n",
    "        file_path = os.path.join(video_folder, file_name)\n",
    "        frame_num = int(re.search(r'frame_(\\d+)', file_name).group(1))\n",
    "        \n",
    "        if frame_num >= num_frames:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            data = np.load(file_path, allow_pickle=True)\n",
    "            if 'pose' in data and data['pose'].shape[0] > 0:\n",
    "                # Store each frame in the correct position\n",
    "                video_features[frame_num, :] = data['pose'].reshape(-1)[:75]  # Use only the first 75 values\n",
    "            else:\n",
    "                print(f\"Warning: Empty or invalid data in {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    # Check the number of empty frames (frames with all zeros)\n",
    "    empty_frames = np.sum(np.all(video_features == 0, axis=1))\n",
    "    if empty_frames > 0:\n",
    "        print(f\"Warning: {empty_frames} empty frames in {os.path.basename(video_folder)}\")\n",
    "    \n",
    "    return video_features\n",
    "\n",
    "def load_all_videos(base_folder, video_order):\n",
    "    all_video_features = []\n",
    "    \n",
    "    for video_name in tqdm(video_order, desc=\"Loading videos\"):\n",
    "        video_folder = os.path.join(base_folder, video_name)\n",
    "        if os.path.isdir(video_folder):\n",
    "            video_features = load_video_features(video_folder)\n",
    "            all_video_features.append(video_features)\n",
    "            print(f\"Complete: {video_name}\")\n",
    "        else:\n",
    "            print(f\"Warning: Folder not found for video {video_name}\")\n",
    "    \n",
    "    all_video_features = np.array(all_video_features)\n",
    "    return all_video_features\n",
    "\n",
    "# Read VID_NAME from CSV file\n",
    "csv_path = './extracted-features/train-data-annotation-v1.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "video_order = df['VID_NAME'].tolist()\n",
    "\n",
    "base_folder = './visual-features-pose/train-talker'\n",
    "train_features = load_all_videos(base_folder, video_order)\n",
    "print(train_features.shape)  # Expected output: (number_of_videos, 3000, 75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "media",
   "language": "python",
   "name": "media"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
